#!/usr/bin/env python
"""
å®Œæ•´çš„ py_dct_txt æµ‹è¯•å¥—ä»¶
åŒ…å«å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•å’Œè¾¹ç•Œæƒ…å†µæµ‹è¯•
"""

import json
import tempfile
import time
from io import StringIO
from pathlib import Path
from unittest.mock import MagicMock, patch

import pytest

from py_dct_txt.py_dct_txt import DctTxt, DctTxtItem, DctTxtStore
from py_dct_txt.utils import (
    extract_inline_comments,
    normalize_to_ascii,
    split_by_first_sep,
    yaml_flow_dumps,
    yaml_flow_loads,
)


class TestUtils:
    """æµ‹è¯•å·¥å…·å‡½æ•°"""

    def test_extract_inline_comments_basic(self):
        """æµ‹è¯•åŸºæœ¬è¡Œå†…æ³¨é‡Šæå–"""
        # æ­£å¸¸æƒ…å†µ
        comments, code = extract_inline_comments("key := value /* è¿™æ˜¯ä¸€ä¸ªæ³¨é‡Š */")
        assert comments == ["/* è¿™æ˜¯ä¸€ä¸ªæ³¨é‡Š */"]
        assert code == "key := value "

        # å¤šä¸ªæ³¨é‡Š
        comments, code = extract_inline_comments("key /* æ³¨é‡Š1 */ := value /* æ³¨é‡Š2 */")
        assert len(comments) == 2
        assert "æ³¨é‡Š1" in comments[0]
        assert "æ³¨é‡Š2" in comments[1]

        # æ— æ³¨é‡Š
        comments, code = extract_inline_comments("key := value")
        assert comments == []
        assert code == "key := value"

    def test_extract_inline_comments_edge_cases(self):
        """æµ‹è¯•è¡Œå†…æ³¨é‡Šè¾¹ç•Œæƒ…å†µ"""
        # ç©ºå­—ç¬¦ä¸²
        comments, code = extract_inline_comments("")
        assert comments == [] and code == ""

        # åªæœ‰æ³¨é‡Š
        comments, code = extract_inline_comments("/* åªæœ‰æ³¨é‡Š */")
        assert comments == ["/* åªæœ‰æ³¨é‡Š */"] and code == ""

        # æ³¨é‡Šåœ¨å¼€å¤´
        comments, code = extract_inline_comments("/* å¼€å¤´æ³¨é‡Š */ key := value")
        assert comments == ["/* å¼€å¤´æ³¨é‡Š */"]
        assert "key := value" in code

    def test_split_by_first_sep(self):
        """æµ‹è¯•æŒ‰ç¬¬ä¸€ä¸ªåˆ†éš”ç¬¦åˆ†å‰²"""
        import re

        pattern = re.compile(r"(:=|=>|>>|<>)")

        # æ­£å¸¸åˆ†éš”ç¬¦
        prefix, sep, suffix = split_by_first_sep(pattern, "key := value")
        assert prefix == "key "
        assert sep == ":="
        assert suffix == " value"

        # æ— åˆ†éš”ç¬¦
        prefix, sep, suffix = split_by_first_sep(pattern, "key value")
        assert prefix == "key value"
        assert sep == ""
        assert suffix == ""

        # åˆ†éš”ç¬¦åœ¨å¼€å¤´
        prefix, sep, suffix = split_by_first_sep(pattern, ":= value")
        assert prefix == ""
        assert sep == ":="
        assert suffix == " value"

        # åˆ†éš”ç¬¦åœ¨ç»“å°¾
        prefix, sep, suffix = split_by_first_sep(pattern, "key :=")
        assert prefix == "key "
        assert sep == ":="
        assert suffix == ""

    def test_yaml_flow_roundtrip(self):
        """æµ‹è¯•YAMLæµæ ¼å¼çš„åºåˆ—åŒ–å’Œååºåˆ—åŒ–"""
        test_data = {"name": "test", "value": 123, "items": [1, 2, 3]}

        # åºåˆ—åŒ–ç„¶åååºåˆ—åŒ–
        yaml_str = yaml_flow_dumps(test_data)
        reconstructed = yaml_flow_loads(yaml_str)

        assert reconstructed == test_data

    def test_yaml_flow_special_values(self):
        """æµ‹è¯•YAMLç‰¹æ®Šå€¼å¤„ç†"""
        # Noneå€¼å¤„ç†
        test_data = {"null_value": None, "list_with_none": [1, None, 3]}
        yaml_str = yaml_flow_dumps(test_data)
        reconstructed = yaml_flow_loads(yaml_str)
        assert reconstructed["null_value"] is None

        # å¸ƒå°”å€¼
        test_data = {"true_val": True, "false_val": False}
        yaml_str = yaml_flow_dumps(test_data)
        reconstructed = yaml_flow_loads(yaml_str)
        assert reconstructed["true_val"] is True
        assert reconstructed["false_val"] is False

        # æµ®ç‚¹æ•°
        test_data = {"float_val": 3.14, "scientific": 1.23e-4}
        yaml_str = yaml_flow_dumps(test_data)
        reconstructed = yaml_flow_loads(yaml_str)
        assert reconstructed["float_val"] == 3.14

    def test_normalize_to_ascii(self):
        """æµ‹è¯•Unicodeåˆ°ASCIIæ ‡å‡†åŒ–"""
        # å¸¦é‡éŸ³ç¬¦å·çš„å­—ç¬¦
        result = normalize_to_ascii("cafÃ©")
        assert result == "cafe"

        # ä¸­æ–‡å­—ç¬¦ï¼ˆåº”ä¿æŒä¸å˜ï¼‰
        result = normalize_to_ascii("ä¸­æ–‡")
        assert result == "ä¸­æ–‡"

        # æ··åˆå­—ç¬¦
        result = normalize_to_ascii("cafÃ©ä¸­æ–‡test")
        assert result == "cafeä¸­æ–‡test"


class TestDctTxt:
    """æµ‹è¯•DctTxtä¸»ç±»"""

    @pytest.fixture
    def dct_txt(self):
        return DctTxt()

    @pytest.fixture
    def sample_data(self):
        """æä¾›ç¤ºä¾‹æ•°æ®"""
        return [
            "/* æ³¨é‡Š1 */ key1 := value1",
            "key2 => value2 /* è¡Œå†…æ³¨é‡Š */",
            "key3 >> [1, 2, 3]",
            "key4 <> name: test, value: 123",
            "",  # ç©ºè¡Œ
            "   ",  # ç©ºç™½è¡Œ
            "key5 := ç®€å•å€¼",
        ]

    @pytest.fixture
    def complex_sample_data(self):
        """æä¾›å¤æ‚ç¤ºä¾‹æ•°æ®"""
        return [
            "/* å¤šè¡Œæ³¨é‡Šå‰å¯¼ */",
            "key1 := å€¼1 || å€¼2 || å€¼3",
            "/* è¡Œå†…æ³¨é‡Šæµ‹è¯• */ key2 => å•å€¼ /* è¡Œå†…æ³¨é‡Š1 */ /* è¡Œå†…æ³¨é‡Š2 */",
            "key3 >> [1, 2, 3, {nested: value}]",
            "key4 <> name: test, enabled: true, count: 123",
            "key5 := ç®€å•å€¼",
            "/*! è„šæœ¬æ³¨é‡Š */ script_key",
        ]

    def test_read_as_list_basic(self, dct_txt, sample_data):
        """æµ‹è¯•åŸºæœ¬åˆ—è¡¨è¯»å–"""
        result = dct_txt.read_as_list(sample_data)

        assert len(result) == 7  # åŒ…å«ç©ºè¡Œå’Œç©ºç™½è¡Œ
        assert result[0][1] == "key1"  # é”®
        assert result[0][2] == ":="  # åˆ†éš”ç¬¦
        assert "value1" in result[0][3]  # å€¼

    def test_read_as_list_complex(self, dct_txt, complex_sample_data):
        """æµ‹è¯•å¤æ‚è§£æåœºæ™¯"""
        result = dct_txt.read_as_list(complex_sample_data)

        # æ£€æŸ¥å¤šå€¼å¤„ç†
        for item in result:
            if item[1] == "key1":
                assert "||" in item[3]  # åº”è¯¥åŒ…å«åˆ†éš”ç¬¦

        # æ£€æŸ¥è„šæœ¬æ³¨é‡Š
        script_items = [item for item in result if item[0].startswith("/*!")]
        assert len(script_items) > 0

    def test_load_dict_basic(self, dct_txt, sample_data):
        """æµ‹è¯•åŸºæœ¬å­—å…¸åŠ è½½"""
        dct_list = dct_txt.read_as_list(sample_data)
        data_dict, globals_dict = dct_txt.load_dict(dct_list)

        assert len(data_dict) > 0
        assert "key1" in data_dict
        assert data_dict["key1"].l == ["value1"]
        assert "key2" in data_dict
        assert data_dict["key2"].s == "value2"

    def test_load_dict_complex(self, dct_txt, complex_sample_data):
        """æµ‹è¯•å¤æ‚å­—å…¸åŠ è½½"""
        dct_list = dct_txt.read_as_list(complex_sample_data)
        data_dict, globals_dict = dct_txt.load_dict(dct_list)

        # æ£€æŸ¥å¤šå€¼åˆ—è¡¨
        key1_item = data_dict.get("key1")
        assert key1_item is not None
        assert len(key1_item.l) == 3

        # æ£€æŸ¥åµŒå¥—å­—å…¸
        key4_item = data_dict.get("key4")
        assert key4_item is not None
        assert "name" in key4_item.kvs
        assert key4_item.kvs["name"] == "test"

    def test_roundtrip_basic(self, dct_txt, sample_data):
        """æµ‹è¯•åŸºæœ¬å¾€è¿”è½¬æ¢"""
        # è¯»å–ä¸ºå­—å…¸
        dct_list = dct_txt.read_as_list(sample_data)
        data_dict, _ = dct_txt.load_dict(dct_list)

        # å†™å›åˆ—è¡¨æ ¼å¼
        new_list = dct_txt.dump_dict(data_dict)

        # åº”è¯¥èƒ½å¤ŸæˆåŠŸè½¬æ¢
        assert len(new_list) > 0

        # é‡æ–°åŠ è½½åº”è¯¥å¾—åˆ°ç›¸åŒç»“æœ
        new_dict, _ = dct_txt.load_dict(new_list)
        assert "key1" in new_dict
        assert new_dict["key1"].l == ["value1"]

    def test_roundtrip_complex(self, dct_txt, complex_sample_data):
        """æµ‹è¯•å¤æ‚æ•°æ®å¾€è¿”è½¬æ¢"""
        dct_list = dct_txt.read_as_list(complex_sample_data)
        data_dict, _ = dct_txt.load_dict(dct_list)
        new_list = dct_txt.dump_dict(data_dict)
        new_dict, _ = dct_txt.load_dict(new_list)

        # éªŒè¯å…³é”®æ•°æ®å®Œæ•´æ€§
        assert "key1" in new_dict
        assert len(new_dict["key1"].l) == 3
        assert "key4" in new_dict
        assert new_dict["key4"].kvs["name"] == "test"

    def test_save_to_file(self, dct_txt, sample_data, tmp_path):
        """æµ‹è¯•ä¿å­˜åˆ°æ–‡ä»¶"""
        dct_list = dct_txt.read_as_list(sample_data)
        data_dict, _ = dct_txt.load_dict(dct_list)

        # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        test_file = tmp_path / "test.dct.txt"
        with open(test_file, "w", encoding="utf-8") as f:
            dct_txt.save_dict(data_dict, f)

        assert test_file.exists()
        assert test_file.stat().st_size > 0

        # éªŒè¯æ–‡ä»¶å†…å®¹å¯é‡æ–°åŠ è½½
        with open(test_file, "r", encoding="utf-8") as f:
            reloaded_dict, _ = dct_txt.read_as_dict(f)
        assert "key1" in reloaded_dict

    def test_error_handling(self, dct_txt):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        # æ— æ•ˆYAMLæ ¼å¼
        invalid_data = ["key >> [1, 2, 3"]  # ç¼ºå°‘é—­åˆæ‹¬å·
        result = dct_txt.read_as_list(invalid_data)
        # åº”è¯¥èƒ½å¤Ÿä¼˜é›…å¤„ç†ï¼Œè€Œä¸æ˜¯å´©æºƒ

        # æ— æ•ˆå­—å…¸æ ¼å¼
        invalid_dict = ["key <> {invalid: json, missing: quote}"]
        result = dct_txt.read_as_list(invalid_dict)
        data_dict, _ = dct_txt.load_dict(result)
        # åº”è¯¥èƒ½å¤Ÿå¤„ç†è§£æé”™è¯¯

    def test_batch_processing(self, dct_txt):
        """æµ‹è¯•æ‰¹é‡å¤„ç†"""
        # ç”Ÿæˆå¤§é‡æµ‹è¯•æ•°æ®
        large_data = [f"key_{i} := value_{i}" for i in range(100)]
        large_data.extend([f"batch_key => batch_value_{i}" for i in range(50)])

        dct_list = dct_txt.read_as_list(large_data)
        data_dict, _ = dct_txt.load_dict(dct_list)

        # æµ‹è¯•åˆ†æ‰¹å¤„ç†
        batches = list(dct_txt.get_list_batch(dct_list, batch_size=30, max_extra=5))

        assert len(batches) >= 2  # åº”è¯¥è‡³å°‘åˆ†æˆ2æ‰¹
        total_items = sum(len(batch) for batch in batches)
        assert total_items == len(dct_list)  # åº”è¯¥ä¿æŒæ€»æ•°ä¸å˜

    def test_format_list_item(self, dct_txt):
        """æµ‹è¯•åˆ—è¡¨é¡¹æ ¼å¼åŒ–"""
        test_item = (
            "/* åŸå§‹æ³¨é‡Š */",
            "key",
            ":=",
            "value",
            ["/* æ³¨é‡Š1 */", "/* æ³¨é‡Š2 */"],
        )
        formatted = dct_txt.format_list_item(test_item)

        assert formatted[0].startswith("/* ")
        assert formatted[0].endswith(" */")
        assert len(formatted[4]) == 2  # æ³¨é‡Šåº”è¯¥è¢«æ­£ç¡®æ ¼å¼åŒ–

    @pytest.mark.parametrize(
        "input_line,expected_key,expected_sep",
        [
            ("key := value", "key", ":="),
            ("key => value", "key", "=>"),
            ("key >> value", "key", ">>"),
            ("key <> value", "key", "<>"),
            ("/* æ³¨é‡Š */ key := value", "key", ":="),
        ],
    )
    def test_separator_parsing_parametrized(
        self, dct_txt, input_line, expected_key, expected_sep
    ):
        """å‚æ•°åŒ–æµ‹è¯•ï¼šæµ‹è¯•ä¸åŒåˆ†éš”ç¬¦çš„è§£æ"""
        result = dct_txt.read_as_list([input_line])

        assert len(result) == 1
        assert result[0][1] == expected_key
        assert result[0][2] == expected_sep


class TestDctTxtStore:
    """æµ‹è¯•DctTxtStoreç±»"""

    @pytest.fixture
    def store(self):
        return DctTxtStore()

    @pytest.fixture
    def sample_files_structure(self, tmp_path):
        """åˆ›å»ºç¤ºä¾‹æ–‡ä»¶ç»“æ„"""
        # åˆ›å»ºå¤šä¸ªåˆ†ç»„æ–‡ä»¶
        groups = {
            "group1": ["key1 := value1", "key2 => value2"],
            "group2": ["key1 := different_value", "key3 >> [1,2,3]"],
            "group3": ["key4 <> {test: true}"],
        }

        for group_name, lines in groups.items():
            group_file = tmp_path / f"{group_name}.dct.txt"
            group_file.write_text("\n".join(lines), encoding="utf-8")

        return tmp_path

    def test_extract_groupname(self):
        """æµ‹è¯•æå–ç»„å"""
        # æ­£å¸¸æ–‡ä»¶å
        assert DctTxtStore.extract_groupname("group1.dct.txt") == "group1"
        assert DctTxtStore.extract_groupname("group1__123.dct.txt") == "group1"
        assert DctTxtStore.extract_groupname("test_group.dct.txt") == "test_group"

        # å¼‚å¸¸æ–‡ä»¶å
        assert DctTxtStore.extract_groupname("invalid.txt") == "unknown"
        assert DctTxtStore.extract_groupname("no_extension") == "unknown"

    def test_create_index_map_basic(self, store):
        """æµ‹è¯•åŸºæœ¬ç´¢å¼•æ˜ å°„åˆ›å»º"""
        keys = ["apple", "banana", "cherry", "123number", "ä¸­æ–‡", "test"]
        index_map = store.create_index_map(keys)

        # å°‘çš„æ—¶å€™ä¸åˆ›å»ºç´¢å¼•
        assert "" in index_map
        assert len(index_map) == 1

        many_keys = [f"a{i}" for i in range(1000)]
        index_map = store.create_index_map(keys + many_keys)

        assert "a" in index_map
        assert len(index_map["a"]) == 1001
        assert "b" in index_map
        assert "c" in index_map
        assert "#" in index_map  # æ•°å­—å’Œä¸­æ–‡åº”è¯¥å½’åˆ°#ç±»åˆ«
        assert len(index_map["#"]) == 2
        assert "t" in index_map

    def test_create_index_map_large(self, store):
        """æµ‹è¯•å¤§é‡é”®çš„ç´¢å¼•æ˜ å°„"""
        # ç”Ÿæˆå¤§é‡æµ‹è¯•é”®
        test_keys = [f"key_{i}" for i in range(2000)]
        test_keys.extend([f"apple_{i}" for i in range(500)])
        test_keys.extend(["123start", "æµ‹è¯•", "Ã©tagÃ¨re"])

        index_map = store.create_index_map(test_keys)

        # éªŒè¯åˆ†ç±»
        assert "k" in index_map
        assert "a" in index_map
        assert "#" in index_map

        # éªŒè¯æ€»æ•°
        total_keys = sum(len(keys) for keys in index_map.values())
        assert total_keys == len(test_keys)

    def test_transpose_dict(self):
        """æµ‹è¯•å­—å…¸è½¬ç½®"""
        nested_dict = {
            "group1": {"key1": "value1", "key2": "value2"},
            "group2": {"key1": "value3", "key3": "value4"},
        }

        # åˆ›å»ºæ¨¡æ‹Ÿçš„DctTxtItemå¯¹è±¡
        item1 = DctTxtItem(k="key1", s="value1")
        item2 = DctTxtItem(k="key2", s="value2")
        item3 = DctTxtItem(k="key1", s="value3")
        item4 = DctTxtItem(k="key3", s="value4")

        nested_dict_with_items = {
            "group1": {"key1": item1, "key2": item2},
            "group2": {"key1": item3, "key3": item4},
        }

        transposed = DctTxtStore.transpose_dict(nested_dict_with_items)

        assert "key1" in transposed
        assert "group1" in transposed["key1"]
        assert "group2" in transposed["key1"]
        assert "key2" in transposed
        assert "key3" in transposed

    def test_load_basic(self, store, sample_files_structure):
        """æµ‹è¯•åŸºæœ¬æ–‡ä»¶åŠ è½½"""
        data = store.load(sample_files_structure)

        assert len(data) > 0
        assert "key1" in data
        # key1 åº”è¯¥å‡ºç°åœ¨ä¸¤ä¸ªåˆ†ç»„ä¸­
        assert len(data["key1"]) == 2
        assert "group1" in data["key1"] and "group2" in data["key1"]

    def test_load_nonexistent_path(self, store, tmp_path):
        """æµ‹è¯•åŠ è½½ä¸å­˜åœ¨çš„è·¯å¾„"""
        non_existent = tmp_path / "nonexistent"
        data = store.load(non_existent)
        assert data == {}  # åº”è¯¥è¿”å›ç©ºå­—å…¸è€Œä¸æ˜¯æŠ¥é”™

    def test_load_empty_file(self, store, tmp_path):
        """æµ‹è¯•åŠ è½½ç©ºæ–‡ä»¶"""
        empty_file = tmp_path / "empty.dct.txt"
        empty_file.write_text("", encoding="utf-8")
        data = store.load(empty_file)
        assert data == {}

    def test_save_and_reload(self, store, sample_files_structure, tmp_path):
        """æµ‹è¯•ä¿å­˜å’Œé‡æ–°åŠ è½½"""
        # å…ˆåŠ è½½æ•°æ®
        data = store.load(sample_files_structure)

        # ä¿å­˜åˆ°æ–°ä½ç½®
        output_dir = tmp_path / "output"
        store.save(data, output_dir)

        # é‡æ–°åŠ è½½ä¿å­˜çš„æ•°æ®
        reloaded_data = store.load(output_dir)

        # éªŒè¯æ•°æ®å®Œæ•´æ€§
        assert "key1" in reloaded_data
        assert len(reloaded_data["key1"]) == 2

    def test_file_line_iter(self, tmp_path):
        """æµ‹è¯•æ–‡ä»¶è¡Œè¿­ä»£å™¨"""
        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        file1 = tmp_path / "test1.dct.txt"
        file2 = tmp_path / "test2.dct.txt"

        file1.write_text("line1\nline2\n", encoding="utf-8")
        file2.write_text("line3\nline4\n", encoding="utf-8")

        lines = list(DctTxtStore.file_line_iter([file1, file2]))
        assert len(lines) == 4
        assert "line1" in lines[0]
        assert "line3" in lines[2]

    def test_clean_empty_folder(self, tmp_path):
        """æµ‹è¯•æ¸…ç†ç©ºæ–‡ä»¶å¤¹"""
        # åˆ›å»ºåµŒå¥—çš„ç©ºæ–‡ä»¶å¤¹
        empty_dir = tmp_path / "empty" / "nested"
        empty_dir.mkdir(parents=True)

        # éªŒè¯æ–‡ä»¶å¤¹å­˜åœ¨
        assert empty_dir.exists()

        # æ¸…ç†ç©ºæ–‡ä»¶å¤¹
        DctTxtStore.clean_empty_folder(tmp_path)

        # ç©ºæ–‡ä»¶å¤¹åº”è¯¥è¢«åˆ é™¤
        assert not empty_dir.exists()
        # ä½†æ ¹ç›®å½•åº”è¯¥ä»ç„¶å­˜åœ¨
        assert tmp_path.exists()


class TestIntegration:
    """é›†æˆæµ‹è¯•"""

    def test_end_to_end_basic(self, tmp_path):
        """åŸºæœ¬ç«¯åˆ°ç«¯æµ‹è¯•"""
        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        test_file = tmp_path / "test_group.dct.txt"
        test_content = """/* æµ‹è¯•æ•°æ® */ test_key := æµ‹è¯•å€¼
another_key => å¦ä¸€ä¸ªå€¼ /* æ³¨é‡Š */
list_key >> [1, 2, 3]
dict_key <> name: test, value: 123
"""
        test_file.write_text(test_content, encoding="utf-8")

        # åŠ è½½æ•°æ®
        store = DctTxtStore()
        data = store.load(tmp_path)

        assert len(data) > 0
        assert "test_key" in data
        assert "another_key" in data
        assert "list_key" in data
        assert "dict_key" in data

        # ä¿å­˜æ•°æ®
        output_dir: Path = tmp_path / "output"
        store.save(data, output_dir)

        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
        # æ²¡æœ‰ index (æ•°é‡ < 1000)
        assert (output_dir / "test_group.dct.txt").exists()

        # é‡æ–°åŠ è½½éªŒè¯
        reloaded_data = store.load(output_dir)
        assert "test_key" in reloaded_data

    def test_end_to_end_large_data(self, tmp_path):
        """å¤§æ•°æ®é‡ç«¯åˆ°ç«¯æµ‹è¯•"""
        # åˆ›å»ºå¤§é‡æµ‹è¯•æ•°æ®
        test_content = []
        for i in range(1000):
            test_content.append(f"key_{i} := value_{i}")
            if i % 10 == 0:
                test_content.append(
                    f"/* æ³¨é‡Š {i} */ batch_key_{i // 10} => batch_value_{i // 10}"
                )

        test_file = tmp_path / "large.dct.txt"
        test_file.write_text("\n".join(test_content), encoding="utf-8")

        # åŠ è½½å’Œå¤„ç†
        store = DctTxtStore()
        data = store.load(tmp_path)

        # ä¿å­˜
        output_dir = tmp_path / "output_large"
        store.save(data, output_dir, batch_size=200)

        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
        # æœ‰ index (æ•°é‡ >= 1000)
        assert (output_dir / "b" / "large.dct.txt").exists()
        assert not (output_dir / "b" / "large__1.dct.txt").exists()
        assert (output_dir / "k" / "large__1.dct.txt").exists()

        # éªŒè¯
        reloaded_data = store.load(output_dir)
        assert len(reloaded_data) >= 1000  # è‡³å°‘1000ä¸ªé”®

    def test_roundtrip_complex_data(self, tmp_path):
        """å¤æ‚æ•°æ®å¾€è¿”æµ‹è¯•"""
        complex_content = """
/* å¤šè¡Œæ³¨é‡Š
   ç¬¬äºŒè¡Œ */
multi_value_key := å€¼1 || å€¼2 || å€¼3 /* è¡Œå†…æ³¨é‡Š */

nested_key >> [1, 2, {"nested": true, "items": [1, 2, 3]}]

config_key <> name: æµ‹è¯•é…ç½®, enabled: true, settings: {timeout: 30, retries: 3}, tags: [é‡è¦, æµ‹è¯•]
"""
        test_file = tmp_path / "complex.dct.txt"
        test_file.write_text(complex_content, encoding="utf-8")

        # å¾€è¿”æµ‹è¯•
        store = DctTxtStore()
        dct_txt = DctTxt()

        # åŠ è½½åŸå§‹æ•°æ®
        original_data = store.load(tmp_path)

        # ä¿å­˜åˆ°æ–°ä½ç½®
        output_dir = tmp_path / "output_complex"
        store.save(original_data, output_dir)

        # é‡æ–°åŠ è½½
        final_data = store.load(output_dir)

        # éªŒè¯å…³é”®æ•°æ®å®Œæ•´æ€§
        assert "multi_value_key" in final_data
        assert "nested_key" in final_data
        assert "config_key" in final_data


class TestPerformance:
    """æ€§èƒ½æµ‹è¯•"""

    def test_large_file_processing(self, tmp_path):
        """æµ‹è¯•å¤§æ–‡ä»¶å¤„ç†æ€§èƒ½"""
        dct_txt = DctTxt()

        # ç”Ÿæˆå¤§æ–‡ä»¶ï¼ˆ1000è¡Œï¼‰
        large_content = []
        for i in range(1000):
            if i % 5 == 0:
                large_content.append(f"/* æ³¨é‡Š {i} */ key_{i} := value_{i}")
            else:
                large_content.append(f"key_{i} => value_{i}")

        test_file = tmp_path / "large.dct.txt"
        test_file.write_text("\n".join(large_content), encoding="utf-8")

        # æ€§èƒ½æµ‹è¯•
        start_time = time.time()

        with open(test_file, "r", encoding="utf-8") as f:
            result = dct_txt.read_as_dict(f)

        end_time = time.time()
        processing_time = end_time - start_time

        # éªŒè¯ç»“æœ
        assert len(result[0]) == 1000
        # å¤„ç†æ—¶é—´åº”è¯¥åœ¨åˆç†èŒƒå›´å†…ï¼ˆé€šå¸¸å°äº1ç§’ï¼‰
        assert processing_time < 5.0, f"å¤„ç†æ—¶é—´è¿‡é•¿: {processing_time}ç§’"

    def test_memory_efficiency(self, tmp_path):
        """æµ‹è¯•å†…å­˜æ•ˆç‡"""
        import tracemalloc

        dct_txt = DctTxt()

        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        test_data = [f"key_{i} := value_{i}" for i in range(1000)]

        tracemalloc.start()

        # æ‰§è¡Œæ“ä½œ
        dct_list = dct_txt.read_as_list(test_data)
        data_dict, _ = dct_txt.load_dict(dct_list)

        current, peak = tracemalloc.get_traced_memory()
        tracemalloc.stop()

        # å³°å€¼å†…å­˜ä½¿ç”¨åº”è¯¥åœ¨åˆç†èŒƒå›´å†…
        assert peak < 10 * 1024 * 1024, f"å†…å­˜ä½¿ç”¨è¿‡é«˜: {peak}å­—èŠ‚"  # å°äº10MB


class TestErrorScenarios:
    """é”™è¯¯åœºæ™¯æµ‹è¯•"""

    @pytest.fixture
    def dct_txt(self):
        return DctTxt()

    def test_malformed_yaml(self, dct_txt):
        """æµ‹è¯•æ ¼å¼é”™è¯¯çš„YAMLå¤„ç†"""
        # ä¸å®Œæ•´çš„YAML
        malformed_data = ["test_key >> [1, 2, 3"]  # ç¼ºå°‘é—­åˆæ‹¬å·
        result = dct_txt.read_as_list(malformed_data)
        data_dict, _ = dct_txt.load_dict(result)

        # åº”è¯¥èƒ½å¤Ÿä¼˜é›…å¤„ç†è€Œä¸å´©æºƒ
        assert True  # åªè¦ä¸æŠ›å‡ºå¼‚å¸¸å°±é€šè¿‡

    def test_malformed_dict(self, dct_txt):
        """æµ‹è¯•æ ¼å¼é”™è¯¯çš„å­—å…¸å¤„ç†"""
        # æ— æ•ˆçš„å­—å…¸è¯­æ³•
        malformed_data = ["test_key <> {invalid: syntax, missing: quotes}"]
        result = dct_txt.read_as_list(malformed_data)
        data_dict, _ = dct_txt.load_dict(result)

        # åº”è¯¥èƒ½å¤Ÿä¼˜é›…å¤„ç†
        assert True

    def test_unicode_handling(self, dct_txt, tmp_path):
        """æµ‹è¯•Unicodeå­—ç¬¦å¤„ç†"""
        # åŒ…å«å„ç§Unicodeå­—ç¬¦
        unicode_content = """
normal_key := æ­£å¸¸å€¼
emoji_key := æµ‹è¯•ğŸ‰è¡¨æƒ…
chinese_key := ä¸­æ–‡æµ‹è¯•
special_key := cafÃ© naÃ¯ve rÃ©sumÃ©
"""
        test_file = tmp_path / "unicode.dct.txt"
        test_file.write_text(unicode_content, encoding="utf-8")

        # åº”è¯¥èƒ½å¤Ÿæ­£ç¡®å¤„ç†
        with open(test_file, "r", encoding="utf-8") as f:
            result = dct_txt.read_as_dict(f)

        assert "normal_key" in result[0]
        assert "emoji_key" in result[0]
        assert "chinese_key" in result[0]
        assert "special_key" in result[0]


# é…ç½®é©±åŠ¨çš„æµ‹è¯•ç”¨ä¾‹
TEST_CASES = [
    {
        "name": "basic_key_value",
        "input": ["key := value"],
        "expected_keys": ["key"],
        "expected_separator": ":=",
    },
    {
        "name": "multiple_values",
        "input": ["key := val1 || val2 || val3"],
        "expected_keys": ["key"],
        "expected_values": 3,
    },
    {
        "name": "with_comments",
        "input": ["/* æ³¨é‡Š */ key => value /* è¡Œå†…æ³¨é‡Š */"],
        "expected_keys": ["key"],
        "has_comments": True,
    },
    {
        "name": "yaml_list",
        "input": ["key >> [1, 2, 3]"],
        "expected_keys": ["key"],
        "expected_separator": ">>",
    },
    {
        "name": "yaml_dict",
        "input": ["key <> {name: test}"],
        "expected_keys": ["key"],
        "expected_separator": "<>",
    },
]


@pytest.mark.parametrize("test_case", TEST_CASES, ids=lambda tc: tc["name"])
def test_config_driven(test_case):
    """é…ç½®é©±åŠ¨çš„æµ‹è¯•"""
    dct_txt = DctTxt()
    result = dct_txt.read_as_list(test_case["input"])
    assert len(result) == len(test_case["input"])

    if "expected_keys" in test_case:
        assert result[0][1] in test_case["expected_keys"]

    if "expected_separator" in test_case:
        assert result[0][2] == test_case["expected_separator"]

    if "expected_values" in test_case:
        data_dict, _ = dct_txt.load_dict(result)
        key = test_case["expected_keys"][0]
        assert len(data_dict[key].l) == test_case["expected_values"]


if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œæµ‹è¯•
    pytest.main([__file__, "-v", "--tb=short"])
